# -*- coding: utf-8 -*-
"""hannanum+tfidf.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PWodOYjrFTwKMZE74hJxGkvSmfeSMl9n
"""
import os 

from konlpy.tag import Hannanum
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer


script_dir = os.path.dirname(__file__)
# 파일의 상대 경로를 지정
relative_path = "../../data/processed/hannanum_dataset.csv"

# 상대 경로를 현재 스크립트 파일의 경로와 조합하여 파일 경로를 얻음
file_path = os.path.join(script_dir, relative_path)

# Excel 파일을 데이터프레임으로 읽어오기
df = pd.read_csv(file_path)


# 'hannanum_nouns' 열의 각 행의 문자열을 콤마로 분리하여 리스트로 변환
df['hannanum_nouns'] = df['hannanum_nouns'].apply(lambda x: x.split(','))

# TF-IDF 벡터화
tfidf_vectorizer = TfidfVectorizer()  
tfidf_matrix = tfidf_vectorizer.fit_transform(df['hannanum_nouns'].apply(lambda x: ' '.join(x)))

# 중요한 단어들을 'tfidf' 열에 추가
important_words = tfidf_vectorizer.get_feature_names_out()
word_tfidf_mapping = {}

for i, row in enumerate(tfidf_matrix):
    word_tfidf_mapping[i] = {}
    for j, word_index in enumerate(row.indices):
        word = important_words[word_index]
        tfidf_score = row.data[j]
        word_tfidf_mapping[i][word] = tfidf_score


# TF-IDF 결과를 DataFrame 출력
# "imp_words" 열에서 콤마로 구분된 단어를 분리하고, 그 갯수에 따라 다른 갯수의 키워드 추출
df['han_tfidf_keywords'] = df['imp_words'].apply(lambda words: list(word_tfidf_mapping[i].keys())[:len(words.split(','))])
df['han_tfidf_scores'] = df['han_tfidf_keywords'].apply(lambda keywords: [word_tfidf_mapping[i][keyword] for keyword in keywords])




n_script_dir = os.path.dirname(__file__)
n_relative_path = "../../data/result/hannanum_tfidf.csv"
n_file_path = os.path.join(n_script_dir, n_relative_path)
df.to_csv(n_file_path, index=False)

