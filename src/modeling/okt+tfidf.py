# -*- coding: utf-8 -*-
"""okt+tfidf.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y9UzKae3GnGyxXc-ykKIRNhtKaTtUmXx
"""

pip install scikit-learn

from sklearn.feature_extraction.text import TfidfVectorizer
import pandas as pd

df=pd.read_csv('/content/drive/MyDrive/ai해커톤 개인/최종 데이터셋(수정본_1).csv의 사본',encoding='CP949')

df.drop('번호',axis=1,inplace=True)

df

pip install konlpy

from konlpy.tag import Okt

okt=Okt()

#df_sliced = df.iloc[:10]

nouns_list=[]
for i in range(len(df)):
  text=df.iloc[i,0]
  nouns=okt.nouns(text)
  nouns_list.append(nouns)

df['Okt_Nouns']=nouns_list

df

# TF-IDF 벡터화
tfidf_vectorizer = TfidfVectorizer()
tfidf_matrix = tfidf_vectorizer.fit_transform(df['Okt_Nouns'].apply(lambda x: ' '.join(x)))

# 중요한 단어들을 'tfidf' 열에 추가
important_words = tfidf_vectorizer.get_feature_names_out()
word_tfidf_mapping = {}

for i, row in enumerate(tfidf_matrix):
    word_tfidf_mapping[i] = {}
    for j, word_index in enumerate(row.indices):
        word = important_words[word_index]
        tfidf_score = row.data[j]
        word_tfidf_mapping[i][word] = tfidf_score

# 'tfidf' 열에 단어와 해당 TF-IDF 가중치를 추가
df['tfidf'] = [word_tfidf_mapping[i] for i in range(len(df))]

# TF-IDF 결과를 DataFrame 출력
df

df.to_csv('/content/drive/MyDrive/ai해커톤 개인/binkani_okt_tfidf.csv')

